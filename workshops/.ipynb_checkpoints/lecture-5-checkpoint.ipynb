{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **R scripts for Lecture 5**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This code loads a compiled version of JAGS and rjags from a zip file on Onedrive, and loads rjags. It should only take a few seconds.\n#IMPORTANT: Go to the Kaggle Settings (right hand side click on K icon) and enable the Internet option in Settings before running this.\nsystem(\"wget --no-check-certificate -r 'https://uoe-my.sharepoint.com/:u:/g/personal/dpaulin_ed_ac_uk/EX_-yUc-bIZJhLXHcZxpOj8Ba6dwC15X_MjYoox-xM2KlQ?download=1' -O /kaggle/working/kaggle_JAGS.zip\")\nsystem(\"unzip /kaggle/working/kaggle_JAGS.zip\")\nsystem(\"rm /kaggle/working/kaggle_JAGS.zip\")\nsystem(\"cd /kaggle/working/JAGS-4.3.0\")\nsystem(\"make install\")\nlibrary(rjags,lib.loc=\"/kaggle/working\")\n#If it ran correctly, you should see \n#Loading required package: coda\n#Linked to JAGS 4.3.0\n#Loaded modules: basemod,bugs\n\n#In case you are still experiencing difficulties with this, please use the following code (this compiles and installs JAGS from the source, it takes 6-7 minutes):\n#system(\"wget https://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/Source/JAGS-4.3.0.tar.gz -P /kaggle/working\")\n#system(\"tar xvfz /kaggle/working/JAGS-4.3.0.tar.gz\")\n#system(\"cd /kaggle/working/JAGS-4.3.0\")\n#system(\"/kaggle/working/JAGS-4.3.0/configure\")\n#system(\"make\")\n#system(\"make install\")\n#install.packages(\"rjags\", lib=\"/kaggle/working\")\n#library(rjags,lib.loc=\"/kaggle/working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Bayesian analysis for the Salmon data ####\n\nrequire(rjags)\n\n\n# Simulated data for Salmons \n\nset.seed(9931)\ntrue.a <- 9.3;  true.b <- 52.7\nJ <- 10\nn.vector <- sample(x=50:100,size=J,replace=TRUE)    \np.vector <- rbeta(J,shape1=true.a,shape2=true.b )\ny.vector <- rbinom(n=J,size=n.vector,prob=p.vector)\n# Comparison of observed and \"real\" survival probabilities\n#round(p.vector,2)\n#round(y.vector/n.vector,2)\n\n# Data\nsalmon.data <- list(J=10,n=n.vector,y=y.vector,\n                    ln.mu.alpha=log(8.1),ln.mu.beta=log(21.3),\n                    sigma.theta=0.70)\n\n# Inits (by quantiles of the priors)\nprob.vec <- c(0.05, 0.30, 0.50, 0.80, 0.95)\nalpha.IVs <- qlnorm(p=prob.vec,meanlog=log(8.1),sdlog=0.70)\n#  2.6  5.6  8.1 14.6 25.6\nbeta.IVs  <- qlnorm(p=prob.vec,meanlog=log(21.3),sdlog=0.70)\n#  6.7 14.8 21.3 38.4 67.4\nsalmon.inits <- list()\nfor(i in 1:5) {\n  salmon.inits[[i]] <- list(alpha=alpha.IVs[i],\n                            beta=beta.IVs[i],\n                            p=rbeta(J,2,3)) #initial values for p's\n}\n\n# Model\nsalmon.model <- \"model{\n\n  #-- Prior for alpha and beta\n  tau.theta   <- 1/pow(sigma.theta,2)\n  alpha ~ dlnorm(ln.mu.alpha,tau.theta)\n  beta  ~ dlnorm(ln.mu.beta,tau.theta)\n\n  #-- pdf for survival probabilities\n  #   and the likelihood for the observed returns\n  for(j in 1:J) {\n    p[j] ~ dbeta(alpha,beta)\n    y[j] ~ dbin(p[j],n[j])\n  }\n \n  expect.survival <- alpha/(alpha+beta)\n } \"\n\n\n# Run JAGS to the completion of the \"adaption\" stage \nburnin           <- 5000\ninference.length <- 50000\nsalmon.res.A <- jags.model(file=textConnection(salmon.model), \n                           data=salmon.data, inits=salmon.inits, \n                           n.chains=length(salmon.inits), \n                           quiet = TRUE)\n\n# Burn-in of 5000 iterations\nupdate(salmon.res.A,n.iter=burnin)\n\n# Longer run for making inferences, assuming chains have converged\nsalmon.res.B <- coda.samples(salmon.res.A, \n                             variable.names=c(\"alpha\",\"beta\",\"expect.survival\",\"p\"),\n                             n.iter=inference.length)\n\n# QUALITY OF THE CONVERGENCE SHOULD BE CHECKED\n# BGR statistic\n#gelman.diag(salmon.res.B)\n\n# Number of effective size of the simulations\neffectiveSize(salmon.res.B)\n\n# Trace plots\n#plot(salmon.res.B)\n\n# BGR plots\ngelman.plot(salmon.res.B)\n\n# Autocorrelation plots\n#autocorr.plot(salmon.res.B)\n\n\n# Summary\nsummary(salmon.res.B)\n\n# Plot of the joint posterior (alpha, beta)\n# Another way of pooling information from all 5 chains\nsalmon.output <- do.call(rbind.data.frame,salmon.res.B)\n# Just work with a random sample from the joint posterior\nx <- sample(1:nrow(salmon.output),2000)\nplot(salmon.output$alpha[x],salmon.output$beta[x],\n     xlab=expression(alpha),ylab=expression(beta),\n     main=expression(paste(\"Joint Posterior for \",alpha,\" and \",beta)))\n\n\n# Contrast the posterior estimates of p to the individual mles\n#---- plot the posterior means\ntemp <- summary(salmon.res.B)\nmy.ylim <- c(0,11)\nmy.xlim <- c(0.0,0.35)\nplot(x=c(0.1,0.2),y=c(0.1,10),type=\"n\",xlab=\"range of p's\",ylab=\"\",\n     main=c(\"Posterior means for p's and obs'd fractions\"),\n     xlim=my.xlim,ylim=my.ylim)\nabline(v=true.a/(true.a+true.b),col=\"blue\",lwd=1.5)\npoints(x=temp$statistics[-(1:3),1],y=1:10,pch=\"B\",col=\"red\")\nsegments(x0=temp$quantiles[-(1:3),\"2.5%\"],y0=1:10,x1=temp$quantiles[-(1:3),\"97.5%\"],\n         y1=1:10,col=\"red\",lty=2)\npoints(x=p.vector,y=1:10,pch=\"T\",col=\"blue\")\nempirical.p <-y.vector/n.vector\nempirical.p.se <- sqrt(empirical.p*(1-empirical.p)/n.vector)\npoints(x=empirical.p,y=(1:10)-0.3,col=\"purple\",pch=\"E\")\nsegments(x0=empirical.p-2*empirical.p.se,y0=(1:10)-0.2,\n         x1=empirical.p+2*empirical.p.se,y1=(1:10)-0.2,lty=2,col=\"black\")\ntext(rep(0.32,J),1:J,paste(\"n=\",n.vector))\nlegend(\"topleft\",legend=c(\"Empirical (p-hat)\",\"Posterior\",\"True\"),\n       col=c(\"black\",\"red\",\"blue\"),pch=c(\"E\",\"B\",\"T\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bayesian analysis for the Radon example - JAGS####\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Bayesian analysis for the Radon example ####\n\n#Loading the Minnesota Radon dataset\nsystem(\"wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1ZH11LXu6KEZM6FmT7EYciktlP7CXrPtj' -O /kaggle/working/Minnesota_radon_data.csv\")\n# You need to enable the Internet in Settings in Kaggle (right hand side menu) before running this\nradon.df<- read.csv(\"/kaggle/working/Minnesota_radon_data.csv\",header=TRUE)\n\n\n# Loading and conditioning Radon data\n#radon.df <- read.csv(file=\"Minnesota_radon_data.csv\",header=TRUE)\nradon.df$logradon <- pmax(log(0.1), log(radon.df$radon) )\nradon.df$j.county <- as.numeric(as.factor(radon.df$county))\nhead(radon.df)\n\n# Description of the data\npar(mfrow=c(2,2))\nhist(radon.df$radon, main = \"Radon\", xlab = \"\", ylab = \"\")\nhist(log(radon.df$radon), main = \"Log Radon\", xlab = \"\", ylab = \"\")\nboxplot(logradon ~ floor, data = radon.df, main=\"Log Radon by Floor\")\nboxplot(logradon ~ county, data = radon.df, main=\"Log Radon by Floor\", ylab=\"\")\npar(mfrow=c(1,1))\n\nsummary(as.numeric(table(radon.df$county)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Radon Identical Model ####\n\nrequire(rjags)\n\n# Data block  #includes hyperparameters\ntau.alpha <- tau.beta <- 0.01\nsigma.ub  <- 10\nradon.ident.data <- list(n=nrow(radon.df),log.radon=radon.df$logradon, \n                         floor=radon.df$floor, sigma.ub=sigma.ub, \n                         tau.alpha=tau.alpha, tau.beta=tau.beta)\n# Initial values\nradon.ident.inits <- function(){\n  list(alpha=rnorm(1,0,1/sqrt(tau.alpha)), \n       beta=rnorm(1,0,1/sqrt(tau.beta)),\n       sigma=runif(1,0,sigma.ub))\n}\n\n# Model\nradon.ident.model <- \"model {\n  #likelihood\n  for(i in 1:n) {\n  log.radon[i] ~ dnorm(mu[i],tau)\n  mu[i] <- alpha + beta*floor[i]\n  }\n  \n  # priors for intercept, slope and sigma\n  alpha ~ dnorm(0,tau.alpha)\n  beta  ~ dnorm(0,tau.beta)\n  tau   <- 1/pow(sigma,2)\n  sigma ~ dunif(0,sigma.ub)\n}\"\n\n# Inference\nradon.ident.res.A <- jags.model(file=textConnection(radon.ident.model),\n                                data=radon.ident.data, inits=radon.ident.inits, n.chains=3, \n                                quiet = TRUE)\nupdate(radon.ident.res.A, n.iter=2000)\nradon.ident.res.B <- coda.samples(radon.ident.res.A,\n                                  variable.names=c(\"alpha\",\"beta\",\"sigma\"), n.iter=10000)\n\n\n# QUALITY OF THE CONVERGENCE SHOULD BE CHECKED (not included) \n\n# Summary\nsummary(radon.ident.res.B)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Radon Independent Model ####\n\n\n# Data block  #includes hyperparameters\nradon.indep.data <- list(n=nrow(radon.df),log.radon=radon.df$logradon, \n                         floor=radon.df$floor, sigma.ub=10, \n                         tau.alpha=0.01, tau.beta=0.01,\n                         j.county=radon.df$j.county, \n                         J=max(radon.df$j.county))\n# Initial values\nradon.indep.inits <- function(){\n  list(alpha=rnorm(max(radon.df$j.county), 0,1/sqrt(tau.alpha)), \n       beta=rnorm(1,0,1/sqrt(tau.beta)),\n       sigma=runif(1,0,sigma.ub))\n}\n\n\n# Model\nradon.indep.model <- \"model {\n  #likelihood\n  for(i in 1:n) {\n    log.radon[i] ~ dnorm(mu[i],tau)\n    mu[i] <- alpha[j.county[i]] + beta*floor[i]\n  }\n\n  # priors for independent intercepts per county\n  for(j in 1:J){\n    alpha[j] ~ dnorm(0,tau.alpha)    \n  }\n\n  # priors for intercept, slope and sigma\n  beta  ~ dnorm(0,tau.beta)\n  tau   <- 1/pow(sigma,2)\n  sigma ~ dunif(0,sigma.ub)\n}\"\n\n\n# Inference\nradon.indep.res.A <- jags.model(file=textConnection(radon.indep.model),\n                                data=radon.indep.data, inits=radon.indep.inits, n.chains=3, \n                                quiet = TRUE)\nupdate(radon.indep.res.A, n.iter=2000)\nradon.indep.res.B <- coda.samples(radon.indep.res.A,\n                                  variable.names=c(\"alpha\",\"beta\",\"sigma\"), n.iter=10000)\n\n# QUALITY OF THE CONVERGENCE SHOULD BE CHECKED (not included) \n\n\n# Summary\nsummary(radon.indep.res.B)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Radon Hierarchical Model ####\n\n\n# Data block  #includes hyperparameters\nradon.hier.data <- list(n=nrow(radon.df),log.radon=radon.df$logradon, \n                        floor=radon.df$floor,\n                        sigma.ub=10, sigma.alpha.ub=20,\n                        tau.mu.alpha=0.01, tau.beta=0.01,\n                        j.county=radon.df$j.county, \n                        J=max(radon.df$j.county))\n# Initial values\nradon.hier.inits <- function(){\n  list(mu.alpha=rnorm(1, 0, 1/sqrt(0.01)), \n       beta=rnorm(1, 0, 1/sqrt(0.01)),\n       sigma=runif(1, 0, 10),\n       sigma.alpha=runif(1, 0, 20))\n}\n\n  \n# Model\nradon.hier.model <- \"model {\n###likelihood\nfor(i in 1:n) {\nlog.radon[i] ~ dnorm(mu[i],tau)\nmu[i] <- alpha[j.county[i]] + beta*floor[i]\n}\n#### priors for independent intercepts per county\nfor(j in 1:J){  alpha[j] ~ dnorm(mu.alpha, tau.alpha)   }\n#### Hyperpriors for mu.alpha and tau.alpha\nmu.alpha    ~ dnorm(0, tau.mu.alpha)\ntau.alpha   <- 1/pow(sigma.alpha,2)\nsigma.alpha ~ dunif(0, sigma.alpha.ub)\n#### priors for intercept, slope and sigma\nbeta  ~ dnorm(0,tau.beta)\ntau   <- 1/pow(sigma,2)\nsigma ~ dunif(0,sigma.ub)\n}\"\n\n\n# Inference\nradon.hier.res.A <- jags.model(file=textConnection(radon.hier.model),\n                               data=radon.hier.data, inits=radon.hier.inits, n.chains=3, \n                               quiet = TRUE)\nupdate(radon.hier.res.A, n.iter=2000)\nradon.hier.res.B <- coda.samples(radon.hier.res.A,\n                                 variable.names=c(\"alpha\",\"mu.alpha\",\"sigma.alpha\",\"beta\",\"sigma\"), \n                                 n.iter=10000)\n\n# QUALITY OF THE CONVERGENCE SHOULD BE CHECKED (not included) \n\n# Summary\nsummary(radon.hier.res.B)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparison of fixed and random effects\nauxsum <- summary(radon.indep.res.B)\nauxmeans <- auxsum$statistics[-(86:87),\"Mean\"]\nauxq025 <- auxsum$quantiles[-(86:87),\"2.5%\"]\nauxq975 <- auxsum$quantiles[-(86:87),\"97.5%\"]\n\nauxsum2 <- summary(radon.hier.res.B)\nauxmeans2 <- auxsum2$statistics[-(86:89),\"Mean\"]\nauxq0252 <- auxsum2$quantiles[-(86:89),\"2.5%\"]\nauxq9752 <- auxsum2$quantiles[-(86:89),\"97.5%\"]\n\nmy.ylim <- range(auxq025,auxq975)\npar(mfrow=c(1,2))\nplot(1:85, auxmeans,xlab=\"Counties\", ylim=my.ylim, ylab=\"\", main=\"County intercepts: Independent Model\", pch=NA)\nabline(h=mean(auxmeans),col=\"firebrick2\", lwd=2)\nsegments(1:85, auxq025, 1:85, auxq975, col = \"gray\")\npoints(1:85, auxmeans, pch=19)\nsegments(50, auxq025[50], 50, auxq975[50], col = \"steelblue4\", lwd=2)\npoints(50, auxmeans[50], pch=19, col = \"dodgerblue2\")\nsegments(70, auxq025[70], 70, auxq975[70], col = \"sienna4\", lwd=2)\npoints(70, auxmeans[70], pch=19, col = \"darkorange2\")\ntitle(sub=paste(\"Unweighted mean Basement=\",round(mean(auxmeans),2)))\n\n\nplot(1:85, auxmeans2,xlab=\"Counties\", ylim=my.ylim, ylab=\"\", main=\"County intercepts: Hierarchical Model\", pch=NA)\nabline(h=auxsum2$statistics[\"mu.alpha\",\"Mean\"],col=\"firebrick2\", lwd=2)\nsegments(1:85, auxq0252, 1:85, auxq9752, col = \"gray\")\npoints(1:85, auxmeans2, pch=19)\nsegments(50, auxq0252[50], 50, auxq9752[50], col = \"steelblue4\", lwd=2)\npoints(50, auxmeans2[50], pch=19, col = \"dodgerblue2\")\nsegments(70, auxq0252[70], 70, auxq9752[70], col = \"sienna4\", lwd=2)\npoints(70, auxmeans2[70], pch=19, col = \"darkorange2\")\ntitle(sub=paste(\"Unweighted mean Basement=\",round(mean(auxmeans2),2)))\npar(mfrow=c(1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bayesian analysis for the Radon example - INLA####\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This code unzips an installation of R-INLA from an online source, and loads INLA\n#IMPORTANT: Go to the Kaggle Settings (right hand side click on K icon) and enable the Internet option in Settings before running this.\nsystem(\"wget --no-check-certificate -r 'https://uoe-my.sharepoint.com/:u:/g/personal/dpaulin_ed_ac_uk/EUNBvDg_EJVFqSZJA3Xz7LsB5cVgqYk0HWWnOp74_Dr28A?download=1' -O /kaggle/working/kaggle_INLA.zip\")\nsystem(\"unzip /kaggle/working/kaggle_INLA.zip\")\nsystem(\"rm /kaggle/working/kaggle_INLA.zip\")\nlibrary(INLA,lib.loc=\"/kaggle/working\")\n#If INLA has been successfully loaded, you should see the following:\n#This is INLA_20.03.17 built 2021-01-02 20:27:47 UTC.\n#See www.r-inla.org/contact-us for how to get help.\n#To enable PARDISO sparse library; see inla.pardiso()\n\n#The following code does the full installation. You can try it if the previous code fails, but this takes longer.\n#install.packages(\"INLA\",repos=c(getOption(\"repos\"),INLA=\"https://inla.r-inla-download.org/R/stable\"), dep=TRUE,lib=\"/kaggle/working\")\n#library(INLA,lib.loc=\"/kaggle/working\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. Identical model**"},{"metadata":{},"cell_type":"markdown","source":"First, we are going to implement the identical model, which is a simple Bayesian linear regression model requiring only fixed effects.\n\nIn this model, we had a Uniform[0,10] prior on $\\sigma$. As in INLA we need to specify the prior on $\\log(\\tau)$ for $\\tau=\\frac{1}{\\sigma^2}$, a simple calculation is needed.\nAs explained in Section 5.3.2 of Bayesian Inference in INLA\n(https://becarioprecario.bitbucket.io/inla-gitbook/ch-priors.html), the corresponding prior on $\\theta=\\log(\\tau)$ can be written as\n$$\\log(\\pi(\\theta))=\\log(\\pi_{\\sigma}(\\exp(-\\theta/2)))-\\theta/2-\\log(2).$$\nIn the specific case of $\\sigma\\sim U[0,b]$, we have $\\pi_{\\sigma}(x)=\\frac{1}{b}$ for $0\\le x\\le b$, and 0 elsewhere. So after rearrangement, it follows that\n$$\\log(\\pi(\\theta))=\\left\\{\\begin{matrix}&-\\log(b)-\\theta/2-\\log(2) &\\text{ if }&\\theta\\ge -2 \\log(b) \\\\ &-\\infty &\\text{ if } &\\theta<-2\\log(b)\\end{matrix}\\right.$$\nWe can imput this prior in INLA using the \"expression:\" string, see the code below.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#In INLA, setting uniform priors on sigma.obs is done using the \n#\"expression:\" string, which allows us to specify the log-density of the prior in \n#a format that is similar to R\n#Due to the fact that we need to specify the prior on the internal parameter\n#theta=log(tau) instead of sigma, computing the corresponding prior on theta is needed\n#See Section 5.3.2 of Bayesian Inference in INLA for more details\n#https://becarioprecario.bitbucket.io/inla-gitbook/ch-priors.html\n\n\nsigma.unif.prior = \"expression:\n  b = 10;\n  log_dens = (theta>=(-2*log(b)))*(-log(b)-theta/2-log(2)) + (theta<(-2*log(b)))*(-Inf);\n  return(log_dens); \n\"\nb=10;\n#prec.prior fixed the uniform prior on sigma by fixing the appropriate prior on theta=log(tau)\n#It is important to specify the initial value of theta at a point where the density is not 0, \n#as then the log-density is -Inf that can lead to some convergence issues\nprec.prior <- list(prec=list(prior = sigma.unif.prior,initial = (-2*log(b)+1), fixed = FALSE))\nprior.beta <- list(mean.intercept = 0, prec.intercept = 0.01,\n                    mean = 0, prec = 0.01)\nm.radon.identical=inla(logradon~1+floor,data=radon.df,family=\"gaussian\",control.family=list(hyper=prec.prior),\n                       control.fixed=prior.beta,control.compute=list(cpo=TRUE,dic=TRUE))\n\nsummary(m.radon.identical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"marginal.tau=m.radon.identical$marginals.hyperpar$`Precision for the Gaussian observations`\n#We could also obtain the same marginal by\n#marginal.tau=m.radon.identical$marginals.hyperpar[[1]]\nmarginal.sigma <- inla.tmarginal(function(tau) tau^(-1/2),marginal.tau)\ncat(\"Summary statistics of sigma\\n\")\ninla.zmarginal(marginal.sigma) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the posterior mean and quantiles are essentially identical with the results we got from JAGS."},{"metadata":{},"cell_type":"markdown","source":"**2. Independent model**"},{"metadata":{},"cell_type":"markdown","source":"Our second model is the the independent model, where each county has an independent random intercept.\nThis can be achieved using random effects in inla, \n$$\\texttt{logradon~0+floor+f(county,model=\"iid\",hyper=prec.prior.random.eff)}$$\nNote that there is no \"global\" intercept in this model, hence we specified it to be 0 in the formula."},{"metadata":{"trusted":true},"cell_type":"code","source":"#In INLA, setting uniform priors on sigma.obs is done using the \n#\"expression:\" string, which allows us to specify the log-density of the prior in \n#a format that is similar to R\n#Due to the fact that we need to specify the prior on the internal parameter\n#theta=log(tau) instead of sigma, computing the corresponding prior on theta is needed\n#See Section 5.3.2 of Bayesian Inference in INLA for more details\n#https://becarioprecario.bitbucket.io/inla-gitbook/ch-priors.html\n\nsigma.unif.prior = \"expression:\n  b = 10;\n  log_dens = (theta>=(-2*log(b)))*(-log(b)-theta/2-log(2)) + (theta<(-2*log(b)))*(-100);\n  return(log_dens); \n\"\nb=10;\n#We select the prior for sigma, which is done by specifying the corresponding prior on tau\nprec.prior <- list(prec=list(prior = sigma.unif.prior,initial = (-2*log(b)+1), fixed = FALSE))\n\n\n#We select the prior for the regression coefficients\nprior.beta <- list(mean.intercept = 0, prec.intercept = 0.01,\n                    mean = 0, prec = 0.01)\n\n#The hyperparameter precision of the random effect is stored on the log-scale, \n#and it has to be input in this form when specifying it\n#fixed=TRUE ensures that it is fixed at its initial value\nprec.prior.random.eff <- list(prec=list(initial = log(0.01), fixed = TRUE))\n\n#The independent model is implemented by adding random effects of the form\n#f(county,model=\"iid\",hyper=prec.prior.random.eff)\n#This means that a single random variable corresponds to each county, with a Gaussian prior with mean 0\n#The hyperparameters of this Gaussian prior (the precision) is specified in prec.prior.random.eff\nm.radon.indep=inla(logradon~0+floor+f(county,model=\"iid\",hyper=prec.prior.random.eff),\n                   data=radon.df,family=\"gaussian\",control.family=list(hyper=prec.prior),\n                   control.fixed=prior.beta,control.compute=list(cpo=TRUE,dic=TRUE))\n\nsummary(m.radon.indep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"marginal.tau=m.radon.indep$marginals.hyperpar$`Precision for the Gaussian observations`\n#We could also obtain the same marginal by\n#marginal.tau=m.radon.indep$marginals.hyperpar[[1]]\nmarginal.sigma <- inla.tmarginal(function(tau) tau^(-1/2),marginal.tau)\ncat(\"Summary statistics of sigma\\n\")\ninla.zmarginal(marginal.sigma) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat(\"Summary statistics of the random effects:\\n\")\nm.radon.indep$summary.random$county","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All of these are essentially identical to the results we got from JAGS."},{"metadata":{},"cell_type":"markdown","source":"**3. Hierarchical model**"},{"metadata":{},"cell_type":"markdown","source":"Our third model is the hierarchical model, where each county has a random intercept, but these share the same mean and variance, and we use some priors on these hyperparameters (i.e. the common mean, and variance).\nThis can be achieved using random effects in inla, \n\n`logradon~1+floor+f(county,model=\"iid\",hyper=prec.prior.random.eff)`.\n\nNote that the common mean of the random intercepts is achieved by having a \"global\" intercept in this model, hence we specified it to be 1 in the formula.\nThe appropriate priors on the hyperparameters are set by choosing prec.prior.random.eff, and also using the `control.family=list(hyper=prec.prior)` and `control.fixed=prior.beta` options, see the code below for more details."},{"metadata":{"trusted":true},"cell_type":"code","source":"#In INLA, setting uniform priors on sigma.obs and sigma.alpha is done using the \n#\"expression:\" string, which allows us to specify the log-density of the prior in \n#a format that is similar to R\n#Due to the fact that we need to specify the prior on the internal parameter\n#theta=log(tau) instead of sigma, computing the corresponding prior on theta is needed\n#See Section 5.3.2 of Bayesian Inference in INLA for more details\n#https://becarioprecario.bitbucket.io/inla-gitbook/ch-priors.html\n\nsigma.unif.prior = \"expression:\n  b = 20;\n  log_dens = (theta>=(-2*log(b)))*(-log(b)-theta/2-log(2)) + (theta<(-2*log(b)))*(-Inf);\n  return(log_dens);\"\nb=20;\nprec.prior <- list(prec=list(prior = sigma.unif.prior,initial = (-2*log(b)+1), fixed = FALSE))\n\n\nprior.beta <- list(mean.intercept = 0, prec.intercept = 0.01,\n                    mean = 0, prec = 0.01)\n\n\nsigma.unif.prior.random.eff = \"expression:\n  b = 20;\n  log_dens = (theta>=(-2*log(b)))*(-log(b)-theta/2-log(2)) + (theta<(-2*log(b)))*(-Inf);\n  return(log_dens);\"\n\nb=20;\nprec.prior.random.eff <- list(prec=list(prior = sigma.unif.prior.random.eff,\n                                        initial = (-2*log(b)+1), fixed = FALSE))\n\n#The random effects are added as f(county,model=\"iid\",hyper=prec.prior.random.eff), where \n#prec.prior.random.eff encodes the prior for the random effect hyperparameter theta=log(tau.alpha)\n#prec.prior encodes the prior on the precision tau.obs of the Gaussian likelihood \n#In this model, we have an intercept that corresponds exactly to mu_alpha\n#We set a Gaussian prior with mean 0 and precision 0.01 on the intercept (mu_alpha) \n#and the regression coefficient of the floor covariate (beta) using prior.beta\nm.radon.hierarchical=inla(logradon~1+floor+f(county,model=\"iid\",hyper=prec.prior.random.eff),data=radon.df,\n                          family=\"gaussian\",control.family=list(hyper=prec.prior),\n                          control.fixed=prior.beta,control.compute=list(cpo=TRUE,dic=TRUE))\n\nsummary(m.radon.hierarchical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"marginal.tau=m.radon.hierarchical$marginals.hyperpar$`Precision for the Gaussian observations`\n#We could also obtain the same marginal by\n#marginal.tau=m.radon.hierarchical$marginals.hyperpar[[1]]\nmarginal.sigma <- inla.tmarginal(function(tau) tau^(-1/2),marginal.tau)\ncat(\"Summary statistics of sigma.obs\\n\")\ninla.zmarginal(marginal.sigma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"marginal.tau2=m.radon.hierarchical$marginals.hyperpar$`Precision for county`\n#We could also obtain the same marginal by\n#marginal.tau2=m.radon.hierarchical$marginals.hyperpar[[2]]\nmarginal.sigma.alpha <- inla.tmarginal(function(tau) tau^(-1/2),marginal.tau2)\ncat(\"Summary statistics of sigma.alpha\\n\")\ninla.zmarginal(marginal.sigma.alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat(\"Summary statistics of the random effects:\\n\")\nm.radon.hierarchical$summary.random$county","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All of these results are essentially identical to the ones we got from JAGS.\n\nFinally, we evaluate Bayesian model comparison criteria for these 3 models."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat(\"Marginal log-likelihood of model 1:\",m.radon.identical$mlik[1],\"\\n\")\ncat(\"Marginal log-likelihood of model 2:\",m.radon.indep$mlik[1],\"\\n\")\ncat(\"Marginal log-likelihood of model 3:\",m.radon.hierarchical$mlik[1],\"\\n\")\n\ncat(\"DIC of model 1:\",m.radon.identical$dic$dic,\"\\n\")\ncat(\"DIC of model 2:\",m.radon.indep$dic$dic,\"\\n\")\ncat(\"DIC of model 3:\",m.radon.hierarchical$dic$dic,\"\\n\")\n\ncat(\"NSLCPO of model 1:\",-sum(log(m.radon.identical$cpo$cpo)),\"\\n\")\ncat(\"NSLCPO of model 2:\",-sum(log(m.radon.indep$cpo$cpo)),\"\\n\")\ncat(\"NSLCPO of model 3:\",-sum(log(m.radon.hierarchical$cpo$cpo)),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is clear that according to all 3 criteria, the hierarchical model (model 3) is offering the best fit on the data."}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}