{"cells":[{"metadata":{},"cell_type":"markdown","source":"**University of Edinburgh**\\\n**School of Mathematics**\\\n**Bayesian Data Analysis, 2020/2021, Semester 2**\\\n**Daniel Paulin & Nicol√≤ Margaritella**\n\n**Solutions for Workshop 5: Bayesian methods for Hierarchical Models (HM)**\n"},{"metadata":{},"cell_type":"markdown","source":"**The purpose of this Practical is to give you experience using Bayesian methods to fit Hierarchical\nModels. The two data sets needed, `dyestuff.csv`, and `wartpid.csv`, are available on Learn but they will be automatically uploaded by the code below.**\n\n# 1.  **Modelling yields of a dye from different input batches.**\n\n**In chemical reactions, the yield measures the amount of reactants produced in a reaction (as\nusually not 100\\% of the reactants are converted to products following the stoichiometry of\nthe reaction). This dataset, `dyestuff.csv`, has 30 records with two fields, `yield` and `batch`.\nYield, the outcome variable, is grams of a \"dyestuff\" called Naphthalene Black 12B. The data\nare the result of a study to see how variation between batches of an intermediate product for\nthe synthesis of the dyestuff, called H-acid, contributed to variation in the yield. Six batches,\nlabeled A, B, C, D, E, and F were randomly sampled at the works manufacture. From each\nbatch five preparations of the dyestuff were made at the laboratory, and then the yield was\nmeasured.**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"system(\"wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1ZK2Ovpk4hbWJzlSrlXuRlg9SnSpbINUJ' -O /kaggle/working/Dyestuff.csv\")\nsystem(\"wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=15fbshTQT3xoo1pS_xGL02zcG98Y_iqiJ' -O /kaggle/working/wartpid.csv\")\n# You need to enable the Internet in Settings in Kaggle (right hand side menu) before running this\ndye.data <- read.csv(\"/kaggle/working/Dyestuff.csv\",header=TRUE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(i) EDA: Produce side-by-side boxplots of the yields for each of the 5 batches (e.g. by using the functions `boxplot` and `split`). What patterns do you observe? What does the variation within each batch look like?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Boxplot\nboxplot(split(dye.data$Yield,dye.data$Batch),main=\"Dyestuff Yields\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(ii) Fit the following non-hierarchical (Independent) model using JAGS:**\n\n$$\\text{yield}_{ji}\\sim N(\\theta_j,\\sigma^2)\\quad j=A,\\dots,F$$\n\n**This is simply a regression analysis with 5 indicator variables representing 5 intercepts.\nFirst, you should recode your index j to a numeric scale by using:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"dye.data$Batch <- as.numeric(as.factor(dye.data$Batch))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Use the following normal priors for the $\\theta$'s and uniform prior for $\\sigma$ [1]:**\n\n$$\\theta_j \\overset{iid}{\\sim}  N(\\mu_\\theta = 1500, \\sigma^2_\\theta = 1000^2) \\quad j = A, B, \\dots, F$$\n\n$$\\sigma \\sim \\text{Unif}(0,700) $$\n\n**Run 3 chains with initial values chosen randomly from the prior distributions.**\n\n[1]As recommended by A. Gelman, Prior distributions for variance parameters in hierarchical models, Bayesian\nAnalysis 1(3):515-533, 2006."},{"metadata":{"trusted":true},"cell_type":"code","source":"#This code loads a compiled version of JAGS and rjags from a zip file on Onedrive, and loads rjags. It should only take a few seconds.\n#IMPORTANT: Go to the Kaggle Settings (right hand side click on K icon) and enable the Internet option in Settings before running this.\nsystem(\"wget --no-check-certificate -r 'https://uoe-my.sharepoint.com/:u:/g/personal/dpaulin_ed_ac_uk/EX_-yUc-bIZJhLXHcZxpOj8Ba6dwC15X_MjYoox-xM2KlQ?download=1' -O /kaggle/working/kaggle_JAGS.zip\")\nsystem(\"unzip /kaggle/working/kaggle_JAGS.zip\")\nsystem(\"rm /kaggle/working/kaggle_JAGS.zip\")\nsystem(\"cd /kaggle/working/JAGS-4.3.0\")\nsystem(\"make install\")\nlibrary(rjags,lib.loc=\"/kaggle/working\")\n#If it ran correctly, you should see \n#Loading required package: coda\n#Linked to JAGS 4.3.0\n#Loaded modules: basemod,bugs\n\n#In case you are still experiencing difficulties with this, please use the following code (this compiles and installs JAGS from the source, it takes 6-7 minutes):\n#system(\"wget https://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/Source/JAGS-4.3.0.tar.gz -P /kaggle/working\")\n#system(\"tar xvfz /kaggle/working/JAGS-4.3.0.tar.gz\")\n#system(\"cd /kaggle/working/JAGS-4.3.0\")\n#system(\"/kaggle/working/JAGS-4.3.0/configure\")\n#system(\"make\")\n#system(\"make install\")\n#install.packages(\"rjags\", lib=\"/kaggle/working\")\n#library(rjags,lib.loc=\"/kaggle/working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set.seed(11)\nrequire(rjags)\nmu.theta <- 1500\nsigma.theta <- 1000\nsigma.ub <- 700\ndye.data$j.batch <- as.numeric(as.factor(dye.data$Batch))\n# data list\ndye.fixed.data <- list(Yield=dye.data$Yield, n=dim(dye.data)[1],\nj.batch=dye.data$j.batch, J=max(dye.data$j.batch),\nmu.theta=mu.theta,sigma.theta=sigma.theta, sigma.ub=sigma.ub)\n# initial values\ndye.fixed.inits <- function(){\nlist(theta=rnorm(max(dye.data$j.batch), mu.theta, sigma.theta),\nsigma=runif(1, 0,sigma.ub))\n}\n# Model\ndye.fixed.model <- \"model {\n#likelihood\nfor(i in 1:n) {\nYield[i] ~ dnorm(theta[j.batch[i]], tau)\n}\n# priors for independent means\nfor(j in 1:J){\ntheta[j] ~ dnorm(mu.theta,tau.theta)\n}\ntau.theta <- 1/pow(sigma.theta,2)\n# prior for variance of the observations\ntau <- 1/pow(sigma,2)\nsigma ~ dunif(0,sigma.ub)\n}\"\n#\ndye.fixed.res.A <- jags.model(file=textConnection(dye.fixed.model),\ndata=dye.fixed.data, inits=dye.fixed.inits, n.chains=3,\nquiet = TRUE)\n#\nupdate(dye.fixed.res.A, n.iter=100)\n#\ndye.fixed.res.B <- coda.samples(dye.fixed.res.A,\nvariable.names=c(\"theta\",\"sigma\"), n.iter=5000)\n#\nsummary(dye.fixed.res.B)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(iii) choose enough burn-in and run length so that you are resonably confident that the chains have converged\n(you can plot the chains and check the Gelman-Rubin plot to check that) and you get at least 5000 effective simulations for every parameter(use the `effectiveSize` function).**"},{"metadata":{"trusted":true},"cell_type":"code","source":"effectiveSize(dye.fixed.res.B)\n## sigma    theta[1]  theta[2]  theta[3]  theta[4]  theta[5] theta[6]\n## 6266.012 14797.205 15402.081 15073.129 16269.901 15000.000 15740.752\nplot(dye.fixed.res.B)\ngelman.plot(dye.fixed.res.B)\n#gelman.diag(dye.fixed.res.B)\n#autocorr.plot(dye.fixed.res.B)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(iv) Compare the posterior means (use the summary command) to the ordinary sample\nmean which can be found by:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sapply(split(dye.data$Yield,dye.data$Batch),mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dye.fixed.summary <- summary(dye.fixed.res.B)\ndye.fixed.summary$statistics[-1,\"Mean\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>Solution</u>: the posterior expected values for the fixed effects are almost equal to the sample means.**"},{"metadata":{},"cell_type":"markdown","source":"**(v) Compute the probability for each batch of having an expected yield greater than\n1500gr according to the fixed effects model. Which batches appear to be significantly\nover- or under-producing Naphthalene Black 12B in average? (Assume that the\ndesired yield is 1500gr). First, join all chains in one dataframe:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join all chains in one data.frame\ndye.fixed.output <- do.call(rbind.data.frame, dye.fixed.res.B)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmean(dye.fixed.output$`theta[1]`>1500)\n## [1] 0.583\nmean(dye.fixed.output$`theta[2]`>1500)\n## [1] 0.890 over \nmean(dye.fixed.output$`theta[3]`>1500)\n## [1] 0.995 over\nmean(dye.fixed.output$`theta[4]`>1500)\n## [1] 0.465\nmean(dye.fixed.output$`theta[5]`>1500)\n## [1] 1 over\nmean(dye.fixed.output$`theta[6]`>1500)\n## [1] 0.096 under","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>Solution</u>: according to the independent model, batches B, C and E are over-\nproducing in mean with a probability of approx. 89%, 99.5% and 100% respectively. Batch\nF is under-producing with a probability of 90.4%.**\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"**(b i) Fit the following hierarchical model**\n\n$$\\text{yield}_{ji}\\sim N(\\theta_j,\\sigma^2)\\quad j=A,\\dots,F$$\n\n$$\\theta_j \\sim N(\\mu_\\theta , \\sigma^2_\\theta) \\quad j = A, \\dots, F$$\n\n**Use these prior distributions for the hyper-parameters.**\n\n$$ \\sigma \\sim \\text{Unif}(0,700) $$\n\n$$ \\mu_\\theta \\sim N(2000,1000^2)$$\n\n$$ \\sigma_\\theta \\sim \\text{Unif}(0,300) $$\n\n- Choose 3 sets of initial values by randomly sampling from the prior distributions.\n  Use a burn-in of 1000 and an inference run of 10 000.\n\n- Calculate the Intraclass Correlation Coefficient (ICC) $\\sigma^{2}_\\theta/(\\sigma^{2}_\\theta +\\sigma^{2})$ either by adding a\n  line in the model code block or by computing the new variable with the chains after\n  the inference process.\n\n- When you execute the `coda.samples` function, have the posteriors for the 3 hyperparameters, the $\\theta$'s and the ICC (if you are computing it inside the model) returned."},{"metadata":{"trusted":true},"cell_type":"code","source":"set.seed(11)\nrequire(rjags)\nmu.mu.theta <- 2000\nsigma.mu.theta <- 1000\nsigma.theta.ub <- 300\nsigma.ub <- 700\ndye.hier.data <- list(Yield=dye.data$Yield, n=dim(dye.data)[1],\nj.batch=dye.data$j.batch, J=max(dye.data$j.batch),\nmu.mu.theta=mu.mu.theta, sigma.mu.theta=sigma.mu.theta,\nsigma.theta.ub=sigma.theta.ub, sigma.ub=sigma.ub)\ndye.hier.inits <- function(){\nlist(theta=rnorm(max(dye.data$j.batch), mu.theta, sigma.theta),\nsigma=runif(1, 0,sigma.ub))\n}\n# Model\ndye.hier.model <- \"model{\n#likelihood\nfor(i in 1:n){\nYield[i] ~ dnorm(theta[j.batch[i]], tau)\n }\n# prior for dependent means\nfor(j in 1:J){\ntheta[j] ~ dnorm(mu.theta,tau.theta)\n }\n# hyperpriors for random effect mean and variance\ntau.theta <- 1/pow(sigma.theta,2)\nsigma.theta ~ dunif(0, sigma.theta.ub)\ntau.mu.theta <- 1/pow(sigma.mu.theta,2)\nmu.theta ~ dnorm(mu.mu.theta, tau.mu.theta)\n# prior for variance of the observations\ntau <- 1/pow(sigma,2)\nsigma ~ dunif(0, sigma.ub)\n# Computed quantities\nICC <- pow(sigma.theta,2)/(pow(sigma.theta,2) + pow(sigma,2))\n}\"\n#\ndye.hier.res.A <- jags.model(file=textConnection(dye.hier.model),\ndata=dye.hier.data, inits=dye.hier.inits, n.chains=3,\nquiet = TRUE)\n#\nupdate(dye.hier.res.A, n.iter=1000)\n#\ndye.hier.res.B <- coda.samples(dye.hier.res.A,\nvariable.names=c(\"theta\",\"sigma\",\"mu.theta\",\"sigma.theta\",\"ICC\"),\nn.iter=20000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(b ii) Carry out the following convergence diagnostic procedures: (1) trace plots (2) BGR, (3) autocorrelation\nplots (4) effective sample size, and (5) the time series corrected MC standard error\ndivided by the standard deviations from the posterior for each parameter. If you are\nsatisfied regarding convergence, report the posterior means and standard deviations\nfor $\\mu_\\theta$, $\\sigma_\\theta$ and $\\sigma$, else increase the burn-in and chain lengths and re-run.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CHECKING THE CHAINS\n#\n# plot(dye.hier.res.B)\n# gelman.diag(dye.hier.res.B)\n# gelman.plot(dye.hier.res.B)\n# autocorr.plot(dye.hier.res.B)\n# effectiveSize(dye.hier.res.B)\ndye.hier.summary <- summary(dye.hier.res.B)\ndye.hier.summary$statistics\ndye.hier.summary$statistics[, \"Time-series SE\"]/\ndye.hier.summary$statistics[, \"SD\"] # MCMC error over SD of the parameters","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(b iii) Compute the probability for each batch of having an expected yield greater than 1500gr according to the hierarchical model and compare the results with the ones\nfor the Independent model.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Join all chains in one data.frame\ndye.hier.output <- do.call(rbind.data.frame, dye.hier.res.B)\n# Fixed effects model, Pr(theta_j > 1500)\n## 1) 0.583\n## 2) 0.890\n## 3) 0.995\n## 4) 0.465\n## 5) 1\n## 6) 0.096\n#\n# Hierarchical model, Pr(theta_j > 1500)\nmean(dye.hier.output$`theta[1]`>1500)\n## [1] 0.684\nmean(dye.hier.output$`theta[2]`>1500)\n## [1] 0.907\nmean(dye.hier.output$`theta[3]`>1500)\n## [1] 0.994\nmean(dye.hier.output$`theta[4]`>1500)\n## [1] 0.583\nmean(dye.hier.output$`theta[5]`>1500)\n## [1] 1\nmean(dye.hier.output$`theta[6]`>1500)\n## [1] 0.228","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>Solution</u>: The major change is that the hierarchical model does not offer so high\nprobability of under-production of the chemical for batch F.**"},{"metadata":{},"cell_type":"markdown","source":"**(b iv) Compare the posterior means (use the summary command)\nto the ordinary sample mean, which can be found by:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sapply(split(dye.data$Yield,dye.data$Batch),mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sapply(split(dye.data$Yield,dye.data$Batch),mean)\n## A    B   C     D    E    F\n## 1505 1528 1564 1498 1600 1470\n#\n# dye.hier.summary <- summary(dye.hier.res.B)\ndye.hier.summary$statistics[-(1:4),\"Mean\"]\n#\n#\nmean(dye.hier.summary$statistics[-(1:4),\"Mean\"])\nsd(dye.hier.summary$statistics[-(1:4),\"Mean\"])\n# vs\nmean(sapply(split(dye.data$Yield,dye.data$Batch),mean))\nsd(sapply(split(dye.data$Yield,dye.data$Batch),mean))\n#","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>Solution</u>: the posterior expected values for the hierarchical model are more similar\nto the overall mean than the raw sample means.**"},{"metadata":{},"cell_type":"markdown","source":"**(b v) What does the posterior for the ICC look like? What does its value mean?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join all chains in one data.frame\ndye.hier.output <- do.call(rbind.data.frame, dye.hier.res.B)\n# If ICC was not computed in the model:\n#dye.hier.output$ICC <- dye.hier.output$sigma.theta^2 /\n#( dye.hier.output$sigma.theta^2 + dye.hier.output$sigma^2 )\nplot(density(dye.hier.output$ICC),main=\"ICC posterior density\")\nmean(dye.hier.output$ICC)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>Solution</u>: The expected value of the ICC is approx. 0.5, which indicates that the variance\nof the data is both observational and caused by the batches. The weight of these\ntwo components is quite uncertain, though.**"},{"metadata":{},"cell_type":"markdown","source":"# 2.  **Modelling the probability of genital warts and Pelvic inflammatory disease (PID).**\n\n**Genital warts and Pelvic inflammatory disease (PID) are conditions that commonly\noccur among adult women. These conditions are typically diagnosed after referral to and\nconsultation with a sexual health physician. A question of relevance to health service providers\nis the extent to which there is clinically relevant variation between physicians in the frequency\nwith which PID and genital warts are diagnosed. The data set `wartpid.csv` is a 23 by 4\nmatrix that consists of records for 23 physicians (`doctor`), identified by a number only, all working at\nthe same Sexual Health Centre, the number of patients they saw (`consults`), the number of\ncases of PID diagnosed (`PID`), and the number of cases of genital warts (`warts`) diagnosed.\nLoad the data into R.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"system(\"wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=15fbshTQT3xoo1pS_xGL02zcG98Y_iqiJ' -O /kaggle/working/wartpid.csv\")\n# You need to enable the Internet in Settings in Kaggle (right hand side menu) before running this\nwartpid.data <- read.csv(\"wartpid.csv\",header=TRUE)\nhead(wartpid.data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(i) Exploratory Data Analysis: Calculate the fraction of wart and fraction of PID diagnoses per patient (consult) for each physician and add them as new variables of the dataframe.**\n\n**Produce the following 4 plots and put them on a single page (use the `par(mfrow=c(2,2))` command:**\n- Barplot of warts fraction by physician (use the `barplot` function with an appropriate value for the `names.arg` argument)\n- Barplot of PID fraction by physician.\n- Barplot of consultations by physician.\n- Scatterplot with smooth fit (`scatter.smooth()`) of wart fraction (Y axis) against PID (X axis) fraction."},{"metadata":{"trusted":true},"cell_type":"code","source":"wartpid.data$PID.frac <- wartpid.data$PID / wartpid.data$consults\nwartpid.data$warts.frac <- wartpid.data$warts / wartpid.data$consults\n#\npar(mfrow=c(2,2),oma=c(0,0,3,0))\nbarplot(wartpid.data$PID.frac, names.arg=wartpid.data$doctor,\nmain=\"PID fraction\")\nbarplot(wartpid.data$warts.frac, names.arg=wartpid.data$doctor,\nmain=\"Warts fraction\")\nscatter.smooth(wartpid.data$warts.frac~wartpid.data$PID.frac,\nylab=\"Warts\",xlab=\"PID\", main=\"Warts vs PID\")\nbarplot(wartpid.data$consults, names.arg=wartpid.data$doctor,\nmain = \"Consultations\" )\npar(mfrow=c(1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(b i) <u>Identical logistic model</u> Fit a simple Bayesian model for the number of warts diagnoses where the probability of diagnose is the same for all physicians. You could set\na Beta(0.5; 0.5) prior for the probability $p$, but, in this case we are going to take another\napproach and set a $N(0; 20^2)$ prior for the $\\text{logit}(p) = \\beta_0$**\n\n**Compute the predictive distribution for replicates of the observations. You can do\nthis by duplicating the line where the likelihood is defined with a different name for\nthe response variable (e.g., `warts.pred[i] ~ dbinom(p, consults[i])`).**"},{"metadata":{"trusted":true},"cell_type":"code","source":"require(rjags)\n# Data block\nwarts.ident.data <- list(n=dim(wartpid.data)[1], warts=wartpid.data$warts,\nconsults=wartpid.data$consults)\n# Initial values\nwarts.ident.inits <- function(){ \nlist(beta0=rnorm(1,0,10))\n }\n# Model\nwarts.ident.model <- \"model{\n#likelihood\nfor(i in 1:n){\nwarts[i] ~ dbinom(p, consults[i])\nwarts.pred[i] ~ dbinom(p, consults[i])\n }\n# prior for the probability\nlogit(p) <- beta0\nbeta0 ~ dnorm(0, 0.0025)\n }\"\n# Inference\nwarts.ident.res.A <- jags.model(file=textConnection(warts.ident.model),\ndata=warts.ident.data, inits=warts.ident.inits, n.chains=3,\nquiet = TRUE)\n#\nupdate(warts.ident.res.A, n.iter=2000)\n#\nwarts.ident.res.B <- coda.samples(warts.ident.res.A,\nvariable.names=c(\"beta0\", \"warts.pred\", \"p\"), n.iter=10000)\nsummary(warts.ident.res.B)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(b ii) Join all the chains in one dataframe. Remember that you can use `do.call(rbind.data.frame, warts.ident.res.B)`.**\n\n**Plot the posterior density (`plot(density(...), xlim=c(0.01, 0.08))`) of the estimation for $p$ and then add points (using the `points` function) or vertical lines for all the observed proportions for the physicians. What do you observe? Do you think all the physicians diagnose the same proportion of warts? Do you think the identical model is good for this data?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"warts.ident.output <- do.call(rbind.data.frame, warts.ident.res.B)\nplot(density(warts.ident.output$p), main=\"p|y\", xlim=c(0.01, 0.08))\npoints(wartpid.data$warts.frac, rep(0,23), col=\"firebrick2\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(b iii) Another way of looking at the same problem. Plot the predictive distributions for\nreplicates of the observations with a line indicating the observed value (see code\nbelow). What do you observe? Do you think the identical model is good for this\ndata?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot all the discrete predictive distributions and the observed values\npar(mfrow=c(6,4),mai=c(0.3,0.3,0.3,0.3))\nfor(i in 1:23){\nauxtable <- table(warts.ident.output[,paste0(\"warts.pred[\",i,\"]\")])\nxaux <- as.numeric(names(auxtable))\nplot(NA, xlim=c(min(xaux), max(xaux)), ylim=c(0,max(auxtable)),\nxlab=\"x\", ylab=\"y\")\nsegments(x0=xaux, y0 = 0, x1=xaux, y1=auxtable)\nabline(v=wartpid.data$warts[i], col=\"firebrick2\", lwd=2)\n }\npar(mfrow=c(1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>Solution</u>: For several physicians (e.g, physicians 8, 15, 19 and 21) the observed number of diagnoses falls in the tails of the predictive distributions. This model lacks some flexibility for the effect of the physician.**"},{"metadata":{},"cell_type":"markdown","source":"**(b iv) Compute the predictive probability for physician 1 of observing less or equal diagnoses in the same amount of consults (considering that the probability of diagnose\nstays the same). This is what is called the 'Bayesian p-value'.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean(warts.ident.output$`warts.pred[1]`<=wartpid.data$warts[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(c i) <u>Hierarchical logistic model</u>. Let us improve the previous model by including a random\neffect of the physician on the probability of diagnosing warts. Set a prior distribution\n$N(0; 10^2)$ for the mean of $\\beta_0$ and a $\\text{Unif}(0; 20)$ for its standard deviation.**\n\n**Once again, do prediction for the replicates of the data. We are going to do predictions considering the particular $p_i$ estimated for each physician (you only have to\nadd the indexing `p[i]` to the code line you introduced on the identical model).**"},{"metadata":{"trusted":true},"cell_type":"code","source":"require(rjags)\n# Data block\nwarts.hier.data <- list(n=dim(wartpid.data)[1], warts=wartpid.data$warts,\nconsults=wartpid.data$consults)\n# Initial values\nwarts.hier.inits <- function(){ \nlist(mu.beta0=rnorm(1,0,10), sigma.beta0=runif(1,0,20))\n}\n# Model\nwarts.hier.model <- \"model{\n#likelihood\nfor(i in 1:n){ \nwarts[i] ~ dbinom(p[i], consults[i])\nwarts.pred[i] ~ dbinom(p[i], consults[i])\nlogit(p[i]) <- beta0[i]\nbeta0[i] ~ dnorm(mu.beta0, tau.beta0)\n }\n# hyperpriors for beta0\nmu.beta0 ~ dnorm(0, 0.01)\ntau.beta0 <- pow(sigma.beta0,-2)\nsigma.beta0 ~ dunif(0, 20)\n }\"\n# Inference\nwarts.hier.res.A <- jags.model(file=textConnection(warts.hier.model),\ndata=warts.hier.data, inits=warts.hier.inits, n.chains=3,\nquiet = TRUE)\n#\nupdate(warts.hier.res.A, n.iter=2000)\n#\nwarts.hier.res.B <- coda.samples(warts.hier.res.A,\nvariable.names=c(\"mu.beta0\", \"sigma.beta0\", \"beta0\", \"warts.pred\", \"p\"),\nn.iter=10000)\n#\nsummary(warts.hier.res.B)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(c ii) Join all the chains in one dataframe and then plot the predictive distributions for replicates of the observations with a line indicating the observed value (see code below). What do you observe? Do you think\nthe hierarchical model provides a better fit for this data than the identical model?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join all the chains in one data.frame\nwarts.hier.output <- do.call(rbind.data.frame, warts.hier.res.B)\n# Plot all the discrete predictive distributions and the observed values\npar(mfrow=c(6,4),mai=c(0.3,0.3,0.3,0.3))\nfor(i in 1:23){ \nauxtable <- table(warts.hier.output[,paste0(\"warts.pred[\",i,\"]\")])\nxaux <- as.numeric(names(auxtable))\nplot(NA, xlim=c(min(xaux), max(xaux)), ylim=c(0,max(auxtable)),\nxlab=\"x\", ylab=\"y\")\nsegments(x0=xaux, y0 = 0, x1=xaux, y1=auxtable)\nabline(v=wartpid.data$warts[i], col=\"firebrick2\", lwd=2)\n }\npar(mfrow=c(1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>Solution</u>: We observe that the prediction fits better the data using the hierarchical\nmodel, as this model can count for the effect of the physician on the proportion of\ndiagnoses.**"},{"metadata":{},"cell_type":"markdown","source":"**(c iii) Compute the predictive probability for physician 1 of observing less or equal diagnoses in the same amount of consults and compare it with the one of the Identical model. Can you explain the difference?**"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean(warts.ident.output$`warts.pred[1]`<=wartpid.data$warts[1])\n#0.09587\nmean(warts.hier.output$`warts.pred[1]`<=wartpid.data$warts[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The probability of at least as many warts as observed by physician 1 is 0.094 according to the identical model, while 0.196 according to the hierarchical model. This seems to suggest that the observation is more reasonable according to the hierarchical model, so that model fits this data point better."},{"metadata":{},"cell_type":"markdown","source":"**(d) Implement the identical and hierarchical logistic models for this dataset in INLA. Compare the model fits using Bayesian model comparison criteria (log marginal likelihood, DIC and NLSCPO) and also by implementing the posterior predictive checks of (b iii) and (c iii) in INLA.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#This code unzips an installation of R-INLA from an online source, and loads INLA\n#IMPORTANT: Go to the Kaggle Settings (right hand side click on K icon) and enable the Internet option in Settings before running this.\nsystem(\"wget --no-check-certificate -r 'https://uoe-my.sharepoint.com/:u:/g/personal/dpaulin_ed_ac_uk/EUNBvDg_EJVFqSZJA3Xz7LsB5cVgqYk0HWWnOp74_Dr28A?download=1' -O /kaggle/working/kaggle_INLA.zip\")\nsystem(\"unzip /kaggle/working/kaggle_INLA.zip\")\nsystem(\"rm /kaggle/working/kaggle_INLA.zip\")\nlibrary(INLA,lib.loc=\"/kaggle/working\")\n#If INLA has been successfully loaded, you should see the following:\n#This is INLA_20.03.17 built 2021-01-02 20:27:47 UTC.\n#See www.r-inla.org/contact-us for how to get help.\n#To enable PARDISO sparse library; see inla.pardiso()\n\n#The following code does the full installation. You can try it if the previous code fails, but this takes longer.\n#install.packages(\"INLA\",repos=c(getOption(\"repos\"),INLA=\"https://inla.r-inla-download.org/R/stable\"), dep=TRUE,lib=\"/kaggle/working\")\n#library(INLA,lib.loc=\"/kaggle/working\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"First, we implement the identical model from part (b). \n\nIn this case, no random effects are needed. The model corresponds to binomial likelihood in INLA, number of consultations per doctor is passed along to INLA using the `Ntrials` parameter (see the code below for more details)."},{"metadata":{"trusted":true},"cell_type":"code","source":"prior.beta <- list(mean.intercept = 0, prec.intercept = 1/(20^2))\nm.warts.identical=inla(warts~1,data=wartpid.data,family=\"binomial\",\n                       control.family=list(link=\"logit\"),\n                       Ntrials=consults,\n                       control.fixed=prior.beta,\n                       control.compute=list(config=TRUE,cpo=TRUE,dic=TRUE))\n#Including control.compute=list(config=TRUE,cpo=TRUE,dic=TRUE\n#allows for posterior sampling, and computes CPO and DIC values\n\nsummary(m.warts.identical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The summary statistics of the intercept $\\beta_0$ are essentially identical to what we got from JAGS."},{"metadata":{"trusted":true},"cell_type":"code","source":"prior.beta <- list(mean.intercept = 0, prec.intercept = 1/(10^2))\n\nsigma.unif.prior.random.eff = \"expression:\n  b = 20;\n  log_dens = (theta>=(-2*log(b)))*(-log(b)-theta/2-log(2)) + (theta<(-2*log(b)))*(-Inf);\n  return(log_dens);\"\n\nb=20;\nprec.prior.random.eff <- list(prec=list(prior = sigma.unif.prior.random.eff,\n                                        initial = (-2*log(b)+1), fixed = FALSE))\n\n\nm.warts.hierarchical=inla(warts~1+f(doctor,model=\"iid\",hyper=prec.prior.random.eff),\n                       data=wartpid.data,family=\"binomial\",\n                       control.family=list(link=\"logit\"),\n                       Ntrials=consults,\n                       control.inla = list(strategy = \"laplace\", npoints = 40),\n                       control.fixed=prior.beta,\n                       control.compute=list(config=TRUE,cpo=TRUE,dic=TRUE))\n#We have added control.inla = list(strategy = \"laplace\", npoints = 40)\n#to increase the number of integration points,\n#which helps with more accurate estimation of tail probabilities \n#that are used in CPO calculations\n#Including control.compute=list(config=TRUE,cpo=TRUE,dic=TRUE\n#allows for posterior sampling, and computes CPO and DIC values\n\nsummary(m.warts.hierarchical)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we compare the models using several Bayesian model comparison criteria."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat(\"Marginal log-likelihood of model 1:\",m.warts.identical$mlik[1],\"\\n\")\ncat(\"Marginal log-likelihood of model 2:\",m.warts.hierarchical$mlik[1],\"\\n\")\n\ncat(\"DIC of model 1:\",m.warts.identical$dic$dic,\"\\n\")\ncat(\"DIC of model 2:\",m.warts.hierarchical$dic$dic,\"\\n\")\n\ncat(\"NSLCPO of model 1:\",-sum(log(m.warts.identical$cpo$cpo)),\"\\n\")\ncat(\"NSLCPO of model 2:\",-sum(log(m.warts.hierarchical$cpo$cpo)),\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, the hierarchical model has the best performance according to all 3 criteria."},{"metadata":{},"cell_type":"markdown","source":"Now we do the posterior predictive checks.\nAs the Predictor variables in the posterior samples of INLA contain the linear predictors ($\\eta_i=\\text{logit}(p_i)$), in order to get the posterior predictive samples, we need to apply the inverse logit function on these linear predictors, and then sample from the Binomial distribution taking into account the appropriate number of consultations. The logit link function is of the form\n$$\\text{logit}(p)=\\log(p/(1-p))=\\log(1-1/(1-p))$$,\nand so the inverse logit function is\n$$\\text{inv.logit}(x)=1/(1+\\exp(-x))$$."},{"metadata":{"trusted":true},"cell_type":"code","source":"inv.logit <- function(x) {\n  return(1/(1+exp(-x)))\n}\n\nnbsamp=10000\nn=nrow(wartpid.data)\nyrep1=matrix(0,nrow=n,ncol=nbsamp)\nyrep2=matrix(0,nrow=n,ncol=nbsamp)\n\nm.warts.identical.samples=inla.posterior.sample(n=nbsamp, result=m.warts.identical)\nm.warts.hierarchical.samples=inla.posterior.sample(n=nbsamp, result=m.warts.hierarchical)\npredictor.samples.identical=inla.posterior.sample.eval(function(...) {Predictor},\nm.warts.identical.samples)\npredictor.samples.hierarchical=inla.posterior.sample.eval(function(...) {Predictor},\nm.warts.hierarchical.samples)\n\nfor (row.num in 1:n){   \nyrep1[row.num,]<- rbinom(n=nbsamp, size=wartpid.data$consults[row.num],\n                         prob=inv.logit(predictor.samples.identical[row.num,]))\nyrep2[row.num,]<- rbinom(n=nbsamp, size=wartpid.data$consults[row.num],\n                         prob=inv.logit(predictor.samples.hierarchical[row.num,]))    \n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final step is to plot these replicated against the true values from the data. This is done in the same way as previously."},{"metadata":{"trusted":true},"cell_type":"code","source":"par(mfrow=c(6,4),mai=c(0.3,0.3,0.3,0.3))\nfor(i in 1:23){ \nauxtable <- table(yrep1[i,])\nxaux <- as.numeric(names(auxtable))\nplot(NA, xlim=c(min(xaux), max(xaux)), ylim=c(0,max(auxtable)),\nxlab=\"x\", ylab=\"y\")\nsegments(x0=xaux, y0 = 0, x1=xaux, y1=auxtable)\nabline(v=wartpid.data$warts[i], col=\"firebrick2\", lwd=2)\n }\npar(mfrow=c(1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"par(mfrow=c(6,4),mai=c(0.3,0.3,0.3,0.3))\nfor(i in 1:23){ \nauxtable <- table(yrep2[i,])\nxaux <- as.numeric(names(auxtable))\nplot(NA, xlim=c(min(xaux), max(xaux)), ylim=c(0,max(auxtable)),\nxlab=\"x\", ylab=\"y\")\nsegments(x0=xaux, y0 = 0, x1=xaux, y1=auxtable)\nabline(v=wartpid.data$warts[i], col=\"firebrick2\", lwd=2)\n }\npar(mfrow=c(1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The plots for posterior predictive model checks are identical to what we got from JAGS. The hierarchical model has significantly better fit since all of the actual values from the data lie in the typical range of the replicates (while for the first model, there are a few of them that are very unlikely according to the replicates). The hierarchical model can account for the effect of the physician on the proportion of diagnoses, which explains the better fit."}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}